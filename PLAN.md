# PRIO 1: Dashboard-Integration â€” Implementierungsplan

## Hauptziel
Die zwei getrennten Welten (CLI/Swarm-System + Dashboard-System) zu einer integrierten LÃ¶sung zusammenfÃ¼hren, sodass ein Non-Coder nach `docker compose up -d` ein funktionierendes Dashboard mit echten Agents hat.

## Architektur-Entscheidungen
- **Wrapper-Approach**: Jeder bestehende Swarm-Agent bekommt einen HTTP-Wrapper-Service
- **Frontend**: EigenstÃ¤ndiger Vite/React-Build
- **Bestehender Code bleibt erhalten** â€” keine Rewrites der Agent-Logik

---

## Ziel-Projektstruktur

```
ai_red_team/
â”œâ”€â”€ docker-compose.yml              â† NEU (ersetzt alten, multi-service)
â”œâ”€â”€ .env.example                    â† ERWEITERT (+ REDSWARM_API_KEY etc.)
â”‚
â”œâ”€â”€ backend/                        â† NEU
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py                     â† aus Dashboard/files.zip (erweitert)
â”‚   â””â”€â”€ adapters/
â”‚       â””â”€â”€ blackboard_bridge.py    â† NEU: Blackboard â†’ HTTP Ãœbersetzer
â”‚
â”œâ”€â”€ frontend/                       â† NEU
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ App.jsx                 â† aus Dashboard/files.zip (erweitert)
â”‚
â”œâ”€â”€ nginx/                          â† NEU
â”‚   â””â”€â”€ nginx.conf
â”‚
â”œâ”€â”€ agents/                         â† NEU (HTTP-Wrapper fÃ¼r jeden Agent)
â”‚   â”œâ”€â”€ base_wrapper.py             â† Gemeinsamer Wrapper-Code
â”‚   â”œâ”€â”€ recon/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ main.py                 â† HTTP-Wrapper um ReconAgent
â”‚   â”œâ”€â”€ exploit/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ execution/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ c4/
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ main.py
â”‚
â”œâ”€â”€ swarm/                          â† UNVERÃ„NDERT (bestehende Logik)
â”œâ”€â”€ modules/                        â† UNVERÃ„NDERT
â”œâ”€â”€ browser/                        â† UNVERÃ„NDERT
â”œâ”€â”€ knowledge/                      â† UNVERÃ„NDERT
â”œâ”€â”€ payloads/                       â† UNVERÃ„NDERT
â”œâ”€â”€ monitor/                        â† UNVERÃ„NDERT (altes Dashboard bleibt als Fallback)
â”œâ”€â”€ scanner.py                      â† UNVERÃ„NDERT
â”œâ”€â”€ main.py                         â† UNVERÃ„NDERT (CLI bleibt funktionsfÃ¤hig)
â””â”€â”€ config.py                       â† UNVERÃ„NDERT
```

---

## Implementierungsschritte

### Schritt 1: Backend-Service erstellen
**Dateien**: `backend/main.py`, `backend/Dockerfile`, `backend/requirements.txt`

- `main.py` aus Dashboard/files.zip extrahieren und erweitern:
  - Mission-Options erweitern um `scan_depth`, `kill_chain_phases`, `attack_vectors`
  - Endpoint `GET /missions/{id}/findings` fÃ¼r Agent-zu-Agent Findings-Austausch
  - Endpoint `POST /missions/{id}/relay` fÃ¼r Inter-Agent-Kommunikation (ersetzt Blackboard-Messaging)
  - Health-Check erweitern mit Redis-Status
- Dockerfile: Python 3.12-slim + FastAPI + Redis + httpx
- requirements.txt: fastapi, uvicorn, redis, httpx, pydantic

### Schritt 2: Blackboard-Bridge Adapter
**Datei**: `backend/adapters/blackboard_bridge.py`

- Klasse `BlackboardBridge` die:
  - Ein lokales Blackboard instanziiert (pro Mission)
  - Alle 500ms das Blackboard pollt auf neue EintrÃ¤ge
  - Neue EintrÃ¤ge in HTTP-Updates Ã¼bersetzt:
    - `intel` â†’ `finding` (severity aus priority gemappt)
    - `exploits` â†’ `finding` mit attack_vector + payload
    - `execution` â†’ `finding` mit success-Flag
    - `tasks` â†’ `log` Events
    - `comms` â†’ `log` Events
  - Fortschritt berechnet aus Tasks (done/total) â†’ `progress` Events
  - An das Backend sendet via `POST /missions/{id}/update`

### Schritt 3: Agent-Wrapper erstellen (4 Wrapper)
**Dateien**: `agents/base_wrapper.py`, `agents/recon/main.py`, etc.

`base_wrapper.py` â€” Gemeinsamer Code:
- FastAPI-App mit `/run` und `/health` Endpoints
- Startup-Hook: Registrierung beim Backend (`POST /agents/register`)
- `send_update()` Helper (identisch mit agent_template.py)
- `BlackboardBridge`-Integration: Startet Bridge als Background-Task

Jeder Agent-Wrapper (`agents/recon/main.py` etc.):
- Importiert den bestehenden Swarm-Agent (z.B. `from swarm.agents.recon_agent import ReconAgent`)
- Beim `/run` Call:
  1. Erstellt ein isoliertes Blackboard fÃ¼r diese Mission
  2. Instanziiert den Agent mit diesem Blackboard + Konfiguration
  3. Startet `BlackboardBridge` als Background-Task (pollt â†’ sendet Updates)
  4. Startet `agent.start()` als Background-Task
  5. Gibt sofort `{"status": "started"}` zurÃ¼ck
- Agent-spezifische Registrierungsdaten:
  - Recon: icon=ğŸ”­, capabilities=[entry-point-discovery, vulnerability-scan, fingerprinting, osint]
  - Exploit: icon=ğŸ’‰, capabilities=[payload-development, rag-poisoning, tool-shadowing, kb-optimization]
  - Execution: icon=âš”ï¸, capabilities=[browser-exploitation, api-attacks, content-poisoning, persistence]
  - C4: icon=ğŸ¯, capabilities=[strategy-planning, kill-chain-tracking, report-generation, swarm-coordination]

### Schritt 4: Frontend-Service erstellen
**Dateien**: `frontend/package.json`, `frontend/vite.config.js`, `frontend/index.html`, `frontend/src/App.jsx`, `frontend/Dockerfile`

- `App.jsx` aus Dashboard/files.zip extrahieren
- Erweiterungen:
  - Module-Verwaltungs-Tab (zeigt verfÃ¼gbare Attack-Module)
  - Kill-Chain-Visualisierung (6 Phasen als Fortschritts-Tracker)
  - Knowledge-Base Stats-Widget (Payloads, Success-Rates)
  - Export-Button fÃ¼r Reports (Markdown-Download)
- Vite-Config: Proxy zu Backend fÃ¼r Entwicklung
- Dockerfile: Node 20 â†’ `npm run build` â†’ nginx:alpine fÃ¼r statische Files

### Schritt 5: Nginx Reverse Proxy
**Datei**: `nginx/nginx.conf`

- `/` â†’ Frontend (React)
- `/api/` â†’ Backend (FastAPI)
- `/ws/` â†’ Backend WebSocket
- SSL-ready (Cert-Pfade vorbereitet)

### Schritt 6: Docker Compose (Multi-Service)
**Datei**: `docker-compose.yml` (Projekt-Root, ersetzt alten)

Services:
1. `redis` â€” Message Broker (redis:7-alpine)
2. `backend` â€” FastAPI (build: ./backend)
3. `frontend` â€” React/Vite (build: ./frontend)
4. `nginx` â€” Reverse Proxy (nginx:alpine, ports 80/443)
5. `agent-recon` â€” Recon Wrapper (build: ./agents/recon, depends: backend)
6. `agent-exploit` â€” Exploit Wrapper (build: ./agents/exploit, depends: backend)
7. `agent-execution` â€” Execution Wrapper (build: ./agents/execution, depends: backend)
8. `agent-c4` â€” C4 Wrapper (build: ./agents/c4, depends: backend)

Networks: `internal` (UIâ†”Backendâ†”Redis), `agents` (Backendâ†”Agents)
Volumes: `redis_data`, `knowledge_db`, `logs`

### Schritt 7: .env.example erweitern
- `REDSWARM_API_KEY` â€” API-Key fÃ¼r Agentâ†”Backend Kommunikation
- `BACKEND_PUBLIC_URL` â€” Ã–ffentliche URL des Backends
- Bestehende Notion-Keys bleiben

### Schritt 8: Verifikation & Test
- `docker compose up -d` starten
- PrÃ¼fen: Alle 4 Agents registrieren sich erfolgreich
- Frontend erreichbar unter localhost
- Test-Mission starten Ã¼ber UI
- Live-Monitor zeigt Echtzeit-Updates
- Findings erscheinen im Report-Tab

---

## Nicht im Scope (bewusst ausgeklammert)
- Modul-Aktivierung/Deaktivierung Ã¼ber UI (â†’ Prio 4)
- Setup-Wizard / One-Click-Install (â†’ Prio 2)
- Notion-Template Duplikation (â†’ Prio 5)
- SSL-Zertifikate / Let's Encrypt Integration
- Persistente Datenbank (Postgres statt In-Memory)

## GeschÃ¤tzte Dateien: ~20 neue Dateien, 0 bestehende geÃ¤ndert
## GeschÃ¤tzter Umfang: ~1500-2000 Zeilen neuer Code
